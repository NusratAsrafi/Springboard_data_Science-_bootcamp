{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f004111a-2fbe-4da6-8936-d2f9a9f7da1b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Import the library\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8b2c4319-fd34-4afc-8c94-c36ac9b140b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   eid       vdate rcount gender  dialysisrenalendstage  asthma  irondef  \\\n",
      "0    1   8/29/2012      0      F                      0       0        0   \n",
      "1    2   5/26/2012     5+      F                      0       0        0   \n",
      "2    3   9/22/2012      1      F                      0       0        0   \n",
      "3    4    8/9/2012      0      F                      0       0        0   \n",
      "4    5  12/20/2012      0      F                      0       0        0   \n",
      "\n",
      "   pneum  substancedependence  psychologicaldisordermajor  ...     glucose  \\\n",
      "0      0                    0                           0  ...  192.476918   \n",
      "1      0                    0                           0  ...   94.078507   \n",
      "2      0                    0                           0  ...  130.530524   \n",
      "3      0                    0                           0  ...  163.377028   \n",
      "4      1                    0                           1  ...   94.886654   \n",
      "\n",
      "   bloodureanitro  creatinine        bmi  pulse  respiration  \\\n",
      "0            12.0    1.390722  30.432418     96          6.5   \n",
      "1             8.0    0.943164  28.460516     61          6.5   \n",
      "2            12.0    1.065750  28.843812     64          6.5   \n",
      "3            12.0    0.906862  27.959007     76          6.5   \n",
      "4            11.5    1.242854  30.258927     67          5.6   \n",
      "\n",
      "   secondarydiagnosisnonicd9  discharged  facid  lengthofstay  \n",
      "0                          4    9/1/2012      B             3  \n",
      "1                          1    6/2/2012      A             7  \n",
      "2                          2   9/25/2012      B             3  \n",
      "3                          1   8/10/2012      A             1  \n",
      "4                          2  12/24/2012      E             4  \n",
      "\n",
      "[5 rows x 28 columns]\n"
     ]
    }
   ],
   "source": [
    "# LOAD the dataset\n",
    "\n",
    "# Read the CSV file into a DataFrame\n",
    "df = pd.read_csv('LengthOfStay.csv')\n",
    "\n",
    "# Display the first few rows of the DataFrame\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "70734f5a-b07b-4bc8-a48f-0472496aa761",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100000 entries, 0 to 99999\n",
      "Data columns (total 28 columns):\n",
      " #   Column                      Non-Null Count   Dtype  \n",
      "---  ------                      --------------   -----  \n",
      " 0   eid                         100000 non-null  int64  \n",
      " 1   vdate                       100000 non-null  object \n",
      " 2   rcount                      100000 non-null  object \n",
      " 3   gender                      100000 non-null  object \n",
      " 4   dialysisrenalendstage       100000 non-null  int64  \n",
      " 5   asthma                      100000 non-null  int64  \n",
      " 6   irondef                     100000 non-null  int64  \n",
      " 7   pneum                       100000 non-null  int64  \n",
      " 8   substancedependence         100000 non-null  int64  \n",
      " 9   psychologicaldisordermajor  100000 non-null  int64  \n",
      " 10  depress                     100000 non-null  int64  \n",
      " 11  psychother                  100000 non-null  int64  \n",
      " 12  fibrosisandother            100000 non-null  int64  \n",
      " 13  malnutrition                100000 non-null  int64  \n",
      " 14  hemo                        100000 non-null  int64  \n",
      " 15  hematocrit                  100000 non-null  float64\n",
      " 16  neutrophils                 100000 non-null  float64\n",
      " 17  sodium                      100000 non-null  float64\n",
      " 18  glucose                     100000 non-null  float64\n",
      " 19  bloodureanitro              100000 non-null  float64\n",
      " 20  creatinine                  100000 non-null  float64\n",
      " 21  bmi                         100000 non-null  float64\n",
      " 22  pulse                       100000 non-null  int64  \n",
      " 23  respiration                 100000 non-null  float64\n",
      " 24  secondarydiagnosisnonicd9   100000 non-null  int64  \n",
      " 25  discharged                  100000 non-null  object \n",
      " 26  facid                       100000 non-null  object \n",
      " 27  lengthofstay                100000 non-null  int64  \n",
      "dtypes: float64(8), int64(15), object(5)\n",
      "memory usage: 21.4+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2305beec-1e01-46e8-8bce-c9ac95c1af56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Classify Length of Stay into \"Short\", \"Medium\", and \"Long\" using qcut\n",
    "df['lengthofstay_class'] = pd.qcut(df['lengthofstay'], q=3, labels=['Short', 'Medium', 'Long'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c86a03c3-a93c-47d8-b236-60bc43254d67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Encode target labels into numeric format (0, 1, 2)\n",
    "le_target = LabelEncoder()\n",
    "df['lengthofstay_class'] = le_target.fit_transform(df['lengthofstay_class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7e2ee7cc-dace-4ae9-82d9-9bbdfdb92879",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert 'vdate' and 'discharged' to datetime\n",
    "df['vdate'] = pd.to_datetime(df['vdate'])\n",
    "df['discharged'] = pd.to_datetime(df['discharged'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a8fdb1d8-8325-438a-9743-d02a77634531",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "# Handle the '5+' value in the 'rcount' column\n",
    "df['rcount'] = df['rcount'].replace('5+', 5)  # You can replace with a different value if necessary\n",
    "df['rcount'] = pd.to_numeric(df['rcount'], errors='coerce')  # Convert to numeric, invalid parsing will be set to NaN\n",
    "\n",
    "# Check for any remaining missing values after conversion\n",
    "print(df['rcount'].isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c73a6d21-4fe0-4d87-aac4-a300563a7963",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Encoding Categorical Features\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "binary_columns = ['gender', 'dialysisrenalendstage', 'asthma', 'irondef', 'pneum', \n",
    "                  'substancedependence', 'psychologicaldisordermajor', 'depress', \n",
    "                  'psychother', 'fibrosisandother', 'malnutrition', 'hemo', \n",
    "                  'secondarydiagnosisnonicd9']\n",
    "\n",
    "le = LabelEncoder()\n",
    "\n",
    "for col in binary_columns:\n",
    "    df[col] = le.fit_transform(df[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "76e8d397-b750-4d5d-b792-31d57986da5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Scaling Numerical Features\n",
    "scaler = StandardScaler()\n",
    "numerical_features = ['hematocrit', 'neutrophils', 'sodium', 'glucose', 'bloodureanitro',\n",
    "                      'creatinine', 'bmi', 'pulse', 'respiration']\n",
    "\n",
    "df[numerical_features] = scaler.fit_transform(df[numerical_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a8ade2bf-ecca-478a-878c-e2feb8fe606b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#6. Split Data into Training and Test Sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "X = df.drop(['lengthofstay', 'eid', 'vdate', 'discharged', 'facid', 'lengthofstay_class'], axis=1)  # Features\n",
    "y = df['lengthofstay_class']  # Target\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "24542d0d-1e97-48d4-830d-a2bcca7eea74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy: 88.97%\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'rf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 15\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mModel Accuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00maccuracy\u001b[38;5;250m \u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m100\u001b[39m\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# Get feature importance\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m feature_importance \u001b[38;5;241m=\u001b[39m rf\u001b[38;5;241m.\u001b[39mfeature_importances_\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m# Create a DataFrame for better visualization\u001b[39;00m\n\u001b[0;32m     18\u001b[0m feature_importance_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame({\n\u001b[0;32m     19\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFeature\u001b[39m\u001b[38;5;124m'\u001b[39m: X\u001b[38;5;241m.\u001b[39mcolumns,\n\u001b[0;32m     20\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mImportance\u001b[39m\u001b[38;5;124m'\u001b[39m: feature_importance\n\u001b[0;32m     21\u001b[0m })\u001b[38;5;241m.\u001b[39msort_values(by\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mImportance\u001b[39m\u001b[38;5;124m'\u001b[39m, ascending\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'rf' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "# 7. Model Training - Random Forest Classifier\n",
    "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# 8. Model Evaluation\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(f'Model Accuracy: {accuracy * 100:.2f}%')\n",
    "\n",
    "\n",
    "# Get feature importance\n",
    "feature_importance = rf.feature_importances_\n",
    "\n",
    "# Create a DataFrame for better visualization\n",
    "feature_importance_df = pd.DataFrame({\n",
    "    'Feature': X.columns,\n",
    "    'Importance': feature_importance\n",
    "}).sort_values(by='Importance', ascending=False)\n",
    "\n",
    "# Display feature importance\n",
    "print(feature_importance_df)\n",
    "\n",
    "# Plot feature importance\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh(feature_importance_df['Feature'], feature_importance_df['Importance'], color='skyblue')\n",
    "plt.xlabel('Importance')\n",
    "plt.title('Feature Importance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dab4667a-6ff1-411d-825d-0ad7db4fa5f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. Train the XGBoost Model\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "model = xgb.XGBClassifier(objective='multi:softmax', num_class=3, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# 8. Model Evaluation\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(f'XGBoost Model Accuracy: {accuracy * 100:.2f}%')\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
    "\n",
    "# 9. Hyperparameter Tuning using GridSearchCV\n",
    "param_grid = {\n",
    "    'learning_rate': [0.01, 0.05, 0.1],\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'n_estimators': [100, 200],\n",
    "    'subsample': [0.8, 1.0],\n",
    "    'colsample_bytree': [0.8, 1.0]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(estimator=model, param_grid=param_grid, scoring='accuracy', \n",
    "                           cv=StratifiedKFold(n_splits=5), verbose=1, n_jobs=-1)\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Best hyperparameters\n",
    "print(f\"Best Hyperparameters: {grid_search.best_params_}\")\n",
    "\n",
    "# Train model with the best hyperparameters\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# Evaluate the tuned model\n",
    "y_pred_tuned = best_model.predict(X_test)\n",
    "accuracy_tuned = accuracy_score(y_test, y_pred_tuned)\n",
    "\n",
    "print(f'XGBoost Model (Tuned) Accuracy: {accuracy_tuned * 100:.2f}%')\n",
    "print(\"Classification Report (Tuned):\\n\", classification_report(y_test, y_pred_tuned))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00a838d6-e870-4c5e-b2e2-20cfe0814dab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
